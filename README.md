
## ðŸ§ª GPU:
1. faster-whisper    = ~1940 GB
2. tts               = ~620  GB
3. Qwen/Qwen3-1.7B   = ~4240 GB
4. Qwen/Qwen3-1.7B   = ~4240 GB
5. Qwen/Qwen2.5-0.5B = ~1200 GB
6. Total GPU         = ~4450 GB (faster-whisper+tts+qwen3-0.6B)
7. Total GPU         = ~6800 GB (faster-whisper+tts+qwen3-1.7B)
8. Total GPU         = ~4200 GB (faster-whisper+tts+Qwen2.5-0.5B)

## ðŸ§ª Qwen/Qwen3-1.7B/0.6B:
1. prompt: 32K
2. Trained on same data sets (sizes)