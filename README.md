
## ðŸ§ª GPU:
1. faster-whisper  = ~1940 GB
2. tts             = ~620  GB
3. Qwen/Qwen3-1.7B = ~4240 GB
4. Qwen/Qwen3-0.6B = ~1780 GB

## ðŸ§ª Qwen/Qwen3-1.7B/0.6B:
1. prompt: 32K
2. Trained on same data sets (sizes)